# AI-Assistant(Local test version)
## How to run
1. Install [llama.cpp](https://github.com/ggerganov/llama.cpp)
2. Put all llama.cpp libs and executable(*llama-server, llama.so, etc*) file in folder **Server/llama.cpp/**
3. run server.sh to start llama-server
    ```sh
    sh server.sh
    ```
    check the parameters to fit your device
4. run **ChatEngine/app.py** to start chat